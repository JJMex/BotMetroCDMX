import os
import time
import requests
import feedparser
import pytz
import re
import base64
from datetime import datetime, timedelta
from ntscraper import Nitter
from bs4 import BeautifulSoup
from fake_useragent import UserAgent

# --- CONFIGURACIÃ“N ---
TOKEN = os.environ.get('TELEGRAM_TOKEN')
ID_GRUPO = os.environ.get('TELEGRAM_CHAT_ID') 
ID_CANAL = os.environ.get('TELEGRAM_CHANNEL_ID') 
DESTINATARIOS = [id_ for id_ in [ID_GRUPO, ID_CANAL] if id_]

# URL RSS (Ventana de 1 hora para frescura)
RSS_URL = "https://news.google.com/rss/search?q=Metro+CDMX+retraso+OR+falla+OR+caos+when:1h&hl=es-419&gl=MX&ceid=MX:es-419"

# Palabras Clave de Problemas
PALABRAS_CLAVE = ["retraso", "marcha lenta", "falla", "desalojo", "humo", "detenido", "caos", "lento", "espera", "sin servicio", "colapso", "afectaciones", "avance", "bloqueo"]
# Palabras de SoluciÃ³n (Para cambiar el semÃ¡foro)
PALABRAS_SOLUCION = ["restablece", "normal", "agiliza", "solucionado", "continuo", "reanuda"]
IGNORAR = ["buenos dÃ­as", "cubrebocas", "tarjeta", "arte", "exposiciÃ³n", "domingos y dÃ­as festivos", "cultura", "museo"]

MAPA_LINEAS = {
    "1": "ğŸ©· L1 (Rosa)", "uno": "ğŸ©· L1 (Rosa)", "rosa": "ğŸ©· L1 (Rosa)",
    "2": "ğŸ’™ L2 (Azul)", "dos": "ğŸ’™ L2 (Azul)", "azul": "ğŸ’™ L2 (Azul)",
    "3": "ğŸ’š L3 (Verde)", "tres": "ğŸ’š L3 (Verde)", "verde": "ğŸ’š L3 (Verde)",
    "4": "ğŸ©µ L4 (Cian)", "cuatro": "ğŸ©µ L4 (Cian)", "cian": "ğŸ©µ L4 (Cian)",
    "5": "ğŸ’› L5 (Amarilla)", "cinco": "ğŸ’› L5 (Amarilla)", "amarilla": "ğŸ’› L5 (Amarilla)",
    "6": "â¤ï¸ L6 (Roja)", "seis": "â¤ï¸ L6 (Roja)", "roja": "â¤ï¸ L6 (Roja)",
    "7": "ğŸ§¡ L7 (Naranja)", "siete": "ğŸ§¡ L7 (Naranja)", "naranja": "ğŸ§¡ L7 (Naranja)",
    "8": "ğŸ’š L8 (Verde)", "ocho": "ğŸ’š L8 (Verde)", 
    "9": "ğŸ¤ L9 (CafÃ©)", "nueve": "ğŸ¤ L9 (CafÃ©)", "cafÃ©": "ğŸ¤ L9 (CafÃ©)",
    "a": "ğŸ’œ LA (FÃ©rrea)", "fÃ©rrea": "ğŸ’œ LA (FÃ©rrea)",
    "b": "ğŸ©¶ LB (Gris)", "gris": "ğŸ©¶ LB (Gris)",
    "12": "ğŸ’› L12 (Dorada)", "doce": "ğŸ’› L12 (Dorada)", "dorada": "ğŸ’› L12 (Dorada)"
}

# Inicializador de Camuflaje
ua = UserAgent()

def get_headers():
    """Genera una identidad falsa aleatoria para cada peticiÃ³n."""
    return {
        'User-Agent': ua.random,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
        'Referer': 'https://www.google.com/'
    }

def enviar_telegram(mensaje):
    if not TOKEN or not DESTINATARIOS: return
    for chat_id in DESTINATARIOS:
        for _ in range(3):
            try:
                url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
                data = {'chat_id': chat_id, 'text': mensaje, 'parse_mode': 'HTML', 'disable_web_page_preview': True}
                requests.post(url, data=data, timeout=10)
                break
            except: time.sleep(1)

def analizar_sentimiento(texto):
    """Determina si la noticia es mala (retraso) o buena (soluciÃ³n)."""
    texto = texto.lower()
    if any(p in texto for p in PALABRAS_SOLUCION):
        return "âœ…" # Verde: Problema resuelto
    return "ğŸš¨" # Rojo: Alerta activa

def detectar_lineas(texto):
    texto = texto.lower()
    detectadas = set()
    for clave, nombre in MAPA_LINEAS.items():
        patrones = [f"lÃ­nea {clave}", f"linea {clave}", f"l{clave} ", f"l-{clave}", f"la {clave} "]
        if len(clave) < 3: patrones = [f"lÃ­nea {clave}", f"linea {clave}", f"l-{clave}"]
        if any(p in texto for p in patrones):
            detectadas.add(nombre)
    
    if detectadas:
        lista = sorted(list(detectadas))
        return "\nâš ï¸ <b>AFECTACIÃ“N:</b> " + ", ".join(lista)
    return ""

def resolver_redireccion_google(url_inicial):
    """
    Motor de resoluciÃ³n de enlaces con Filtro Anti-Basura.
    """
    try:
        session = requests.Session()
        # Usamos identidad falsa
        response = session.get(url_inicial, headers=get_headers(), timeout=10, allow_redirects=True)
        
        # LISTA NEGRA: Dominios que NO son noticias
        basura_domains = [
            "google", "gstatic", "youtube", "blogger", "analytics", "doubleclick", 
            "facebook", "twitter", "instagram", "cloudflare", "w3.org", "schema.org",
            "googletagmanager", "g.co", "goo.gl", "pinterest", "tiktok", "microsoft"
        ]
        
        # Si seguimos atrapados en Google, buscamos la salida
        if "google" in response.url:
            print("   âš ï¸ URL Ofuscada. Iniciando extracciÃ³n quirÃºrgica...")
            
            # 1. BÃšSQUEDA REGEX (Busca cualquier http que no sea google)
            urls_candidatas = re.findall(r'(https?:\/\/[^"\s<>\\]+)', response.text)
            
            mejor_candidato = None
            
            for url in urls_candidatas:
                # Filtros de limpieza
                if any(b in url for b in basura_domains): continue # Es basura
                if len(url) < 25: continue # Es muy corta
                if url.endswith(('.png', '.jpg', '.svg', '.gif', '.js', '.css')): continue # Es un archivo
                
                # Si pasa los filtros, es probable que sea la noticia
                print(f"   ğŸ¯ Candidato VÃ¡lido: {url[:60]}...")
                return session.get(url, headers=get_headers(), timeout=10)

        return response 
        
    except Exception as e:
        print(f"   âŒ Error resolviendo: {e}")
        return None

def espiar_noticia_completa(url):
    try:
        response = resolver_redireccion_google(url)
        
        if response and response.status_code == 200:
            print(f"   â†³ Leyendo sitio real: {response.url[:40]}...")
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Limpieza profunda del HTML
            for tag in soup(["script", "style", "nav", "footer", "header", "aside", "iframe", "form"]):
                tag.extract()
                
            textos = soup.find_all(['p', 'h1', 'h2', 'article'])
            texto_completo = " ".join([t.get_text() for t in textos])
            return texto_completo
    except: pass
    return ""

def revisar_incidentes(ahora):
    incidentes = []
    
    # --- GOOGLE NEWS ---
    try:
        print("ğŸ” Analizando Noticias...")
        feed = feedparser.parse(RSS_URL)
        limite = ahora - timedelta(minutes=65)
        
        for e in feed.entries:
            if hasattr(e, 'published_parsed'):
                f = datetime(*e.published_parsed[:6], tzinfo=pytz.utc).astimezone(ahora.tzinfo)
                if f > limite:
                    titulo = e.title
                    
                    if any(p in titulo.lower() for p in PALABRAS_CLAVE):
                        print(f"ğŸ‘‰ Analizando: {titulo[:40]}...")
                        
                        # 1. Detectar LÃ­neas
                        tag_linea = detectar_lineas(titulo)
                        if not tag_linea:
                            print("   ğŸ•µï¸ Activando escaneo profundo...")
                            texto_web = espiar_noticia_completa(e.link)
                            tag_linea = detectar_lineas(texto_web)
                            if tag_linea: print(f"   âœ… LÃ­neas detectadas: {tag_linea}")
                            else: print("   âŒ No se encontraron lÃ­neas.")
                        
                        # 2. Analizar Sentimiento (Rojo o Verde)
                        emoji_estado = analizar_sentimiento(titulo)
                        
                        incidentes.append(f"{emoji_estado} <b>REPORTE:</b> {titulo}{tag_linea}\nğŸ”— <a href='{e.link}'>Ver Nota</a>")
    except Exception as e: print(f"Error RSS: {e}")

    # --- TWITTER (Nitter) ---
    instancias = ["nitter.privacydev.net", "nitter.net", "nitter.cz"]
    for instancia in instancias:
        try:
            print(f"ğŸ¦… Nitter ({instancia})...")
            scraper = Nitter(log_level=1, skip_instance_check=False, instance=instancia)
            data = scraper.get_tweets("MetroCDMX", mode='user', number=5)
            if data and 'tweets' in data:
                for t in data['tweets']:
                    txt = t['text'].lower()
                    if any(p in txt for p in PALABRAS_CLAVE) and not any(i in txt for i in IGNORAR):
                        if "m" in t['date'] or "1h" in t['date']:
                             tag_linea = detectar_lineas(txt)
                             emoji_estado = analizar_sentimiento(txt)
                             incidentes.append(f"{emoji_estado} <b>AVISO OFICIAL:</b> {t['text']}{tag_linea}\nğŸ”— <a href='{t['link']}'>Ver Tweet</a>")
                break 
        except: continue

    return incidentes

def verificar_horario_servicio(ahora):
    dia = ahora.weekday(); hora = ahora.hour
    if dia <= 4 and hora == 5: return "ğŸš‡ <b>INICIO DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLa red del Metro inicia operaciones."
    elif dia == 5 and hora == 6: return "ğŸš‡ <b>INICIO DE SERVICIO (SÃBADO)</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nInicia operaciÃ³n de fin de semana."
    elif dia == 6 and hora == 7: return "ğŸš‡ <b>INICIO DE SERVICIO (DOMINGO)</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nServicio dominical iniciado."
    elif hora == 0: return "ğŸ’¤ <b>CIERRE DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nOperaciones concluidas por hoy."
    return None

def main():
    tz_mx = pytz.timezone('America/Mexico_City')
    ahora = datetime.now(tz_mx)
    print(f"ğŸ Escaneo iniciado: {ahora}")
    
    # Ping de conexiÃ³n
    enviar_telegram("ğŸ“¡ <i>Conectando con la red de movilidad y analizando reportes ciudadanos...</i>")
    time.sleep(1) # PequeÃ±a pausa
    
    msg = verificar_horario_servicio(ahora)
    if msg: enviar_telegram(msg); return

    reportes = revisar_incidentes(ahora)
    if reportes:
        un = list(dict.fromkeys(reportes))
        h = ahora.strftime('%I:%M %p')
        enviar_telegram(f"ğŸ“¢ <b>ACTUALIZACIÃ“N ({h})</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n" + "\n\n".join(un))
    else:
        # Mensaje de normalidad
        enviar_telegram("âœ… <b>Estado del Metro:</b> Sin reportes crÃ­ticos en la Ãºltima hora.\n<i>Sistema operando con normalidad.</i>")
        print("âœ… Todo normal.")

if __name__ == "__main__":
    main()
