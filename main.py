import os
import time
import requests
import feedparser
import pytz
import re
from datetime import datetime, timedelta
from ntscraper import Nitter
from bs4 import BeautifulSoup

# --- CONFIGURACIÃ“N ---
TOKEN = os.environ.get('TELEGRAM_TOKEN')
ID_GRUPO = os.environ.get('TELEGRAM_CHAT_ID') 
ID_CANAL = os.environ.get('TELEGRAM_CHANNEL_ID') 
DESTINATARIOS = [id_ for id_ in [ID_GRUPO, ID_CANAL] if id_]

RSS_URL = "https://news.google.com/rss/search?q=Metro+CDMX+retraso+OR+falla+OR+caos+when:1h&hl=es-419&gl=MX&ceid=MX:es-419"
PALABRAS_CLAVE = ["retraso", "marcha lenta", "falla", "desalojo", "humo", "detenido", "caos", "lento", "espera", "sin servicio", "colapso", "afectaciones", "avance"]
IGNORAR = ["buenos dÃ­as", "cubrebocas", "tarjeta", "arte", "exposiciÃ³n", "domingos y dÃ­as festivos", "cultura"]

MAPA_LINEAS = {
    "1": "ğŸ©· LÃ­nea 1 (Rosa)", "uno": "ğŸ©· LÃ­nea 1 (Rosa)", "rosa": "ğŸ©· LÃ­nea 1 (Rosa)",
    "2": "ğŸ’™ LÃ­nea 2 (Azul)", "dos": "ğŸ’™ LÃ­nea 2 (Azul)", "azul": "ğŸ’™ LÃ­nea 2 (Azul)",
    "3": "ğŸ’š LÃ­nea 3 (Verde)", "tres": "ğŸ’š LÃ­nea 3 (Verde)", "verde": "ğŸ’š LÃ­nea 3 (Verde)",
    "4": "ğŸ©µ LÃ­nea 4 (Cian)", "cuatro": "ğŸ©µ LÃ­nea 4 (Cian)", "cian": "ğŸ©µ LÃ­nea 4 (Cian)",
    "5": "ğŸ’› LÃ­nea 5 (Amarilla)", "cinco": "ğŸ’› LÃ­nea 5 (Amarilla)", "amarilla": "ğŸ’› LÃ­nea 5 (Amarilla)",
    "6": "â¤ï¸ LÃ­nea 6 (Roja)", "seis": "â¤ï¸ LÃ­nea 6 (Roja)", "roja": "â¤ï¸ LÃ­nea 6 (Roja)",
    "7": "ğŸ§¡ LÃ­nea 7 (Naranja)", "siete": "ğŸ§¡ LÃ­nea 7 (Naranja)", "naranja": "ğŸ§¡ LÃ­nea 7 (Naranja)",
    "8": "ğŸ’š LÃ­nea 8 (Verde)", "ocho": "ğŸ’š LÃ­nea 8 (Verde)", 
    "9": "ğŸ¤ LÃ­nea 9 (CafÃ©)", "nueve": "ğŸ¤ LÃ­nea 9 (CafÃ©)", "cafÃ©": "ğŸ¤ LÃ­nea 9 (CafÃ©)",
    "a": "ğŸ’œ LÃ­nea A (FÃ©rrea)", "fÃ©rrea": "ğŸ’œ LÃ­nea A (FÃ©rrea)",
    "b": "ğŸ©¶ LÃ­nea B (Gris)", "gris": "ğŸ©¶ LÃ­nea B (Gris)",
    "12": "ğŸ’› LÃ­nea 12 (Dorada)", "doce": "ğŸ’› LÃ­nea 12 (Dorada)", "dorada": "ğŸ’› LÃ­nea 12 (Dorada)"
}

def enviar_telegram(mensaje):
    if not TOKEN or not DESTINATARIOS: return
    for chat_id in DESTINATARIOS:
        for _ in range(3):
            try:
                url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
                data = {'chat_id': chat_id, 'text': mensaje, 'parse_mode': 'HTML', 'disable_web_page_preview': True}
                requests.post(url, data=data, timeout=10)
                break
            except: time.sleep(1)

def detectar_lineas(texto):
    texto = texto.lower()
    detectadas = set()
    for clave, nombre in MAPA_LINEAS.items():
        patrones = [f"lÃ­nea {clave}", f"linea {clave}", f"l{clave} ", f"l-{clave}", f"la {clave} "]
        if len(clave) < 3: patrones = [f"lÃ­nea {clave}", f"linea {clave}", f"l-{clave}"]
        if any(p in texto for p in patrones):
            detectadas.add(nombre)
    if detectadas:
        return "\nâš ï¸ <b>AFECTACIÃ“N CONFIRMADA:</b> " + ", ".join(sorted(list(detectadas)))
    return ""

def resolver_redireccion_google(url_inicial):
    """
    Mejorado: Filtra imÃ¡genes y URLs de Google para encontrar la noticia real.
    """
    try:
        session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        }
        
        response = session.get(url_inicial, headers=headers, timeout=10, allow_redirects=True)
        
        # DOMINIOS BASURA A IGNORAR
        ignorar_dominios = [
            "googleusercontent.com", "gstatic.com", "w3.org", "schema.org", 
            "googletagmanager.com", "google.com", "youtube.com", "blogger.com"
        ]
        
        if "news.google.com" in response.url:
            print("   âš ï¸ Atrapado en Google. Filtrando URLs basura...")
            texto_html = response.text
            
            # Buscamos TODAS las URLs posibles
            urls_encontradas = re.findall(r'(https?:\/\/[^"\s<>\\]+)', texto_html)
            
            for url_candidata in urls_encontradas:
                # 1. Filtro: Si contiene dominios basura, la saltamos
                if any(basura in url_candidata for basura in ignorar_dominios):
                    continue
                
                # 2. Filtro: Debe ser una URL razonablemente larga (evitar api calls cortas)
                if len(url_candidata) > 25:
                    print(f"   ğŸ¯ URL Limpia encontrada: {url_candidata}")
                    return session.get(url_candidata, headers=headers, timeout=10)
        
        return response 
        
    except Exception as e:
        print(f"   âŒ Error resolviendo URL: {e}")
        return None

def espiar_noticia_completa(url):
    try:
        response = resolver_redireccion_google(url)
        
        if response and response.status_code == 200:
            print(f"   â†³ Leyendo sitio: {response.url[:50]}...")
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Limpiamos basura del HTML
            for tag in soup(["script", "style", "nav", "footer", "header"]):
                tag.extract()
                
            textos = soup.find_all(['p', 'h1', 'h2', 'article'])
            texto_completo = " ".join([t.get_text() for t in textos])
            return texto_completo
    except Exception as e:
        print(f"   â†³ Error espiando: {e}")
    return ""

def revisar_incidentes(ahora):
    incidentes = []
    
    # --- GOOGLE NEWS ---
    try:
        print("ğŸ” Analizando Noticias...")
        feed = feedparser.parse(RSS_URL)
        limite = ahora - timedelta(minutes=65)
        
        for e in feed.entries:
            if hasattr(e, 'published_parsed'):
                f = datetime(*e.published_parsed[:6], tzinfo=pytz.utc).astimezone(ahora.tzinfo)
                if f > limite:
                    titulo = e.title
                    if any(p in titulo.lower() for p in PALABRAS_CLAVE):
                        print(f"ğŸ‘‰ Analizando: {titulo[:30]}...")
                        
                        tag_linea = detectar_lineas(titulo)
                        
                        if not tag_linea:
                            print("   ğŸ•µï¸ Activando escaneo profundo...")
                            texto_web = espiar_noticia_completa(e.link)
                            tag_linea = detectar_lineas(texto_web)
                            if tag_linea: print(f"   âœ… Â¡LÃ­neas detectadas!: {tag_linea}")
                            else: print("   âŒ No se encontraron lÃ­neas.")
                        
                        incidentes.append(f"ğŸ“° <b>NOTICIA:</b> {titulo}{tag_linea}\nğŸ”— <a href='{e.link}'>Ver Nota</a>")
    except Exception as e: print(f"Error RSS: {e}")

    # --- TWITTER (Nitter) ---
    instancias = ["nitter.privacydev.net", "nitter.net", "nitter.cz"]
    for instancia in instancias:
        try:
            print(f"ğŸ¦… Nitter ({instancia})...")
            scraper = Nitter(log_level=1, skip_instance_check=False, instance=instancia)
            data = scraper.get_tweets("MetroCDMX", mode='user', number=5)
            if data and 'tweets' in data:
                for t in data['tweets']:
                    txt = t['text'].lower()
                    if any(p in txt for p in PALABRAS_CLAVE) and not any(i in txt for i in IGNORAR):
                        if "m" in t['date'] or "1h" in t['date']:
                             tag_linea = detectar_lineas(txt)
                             incidentes.append(f"ğŸš¨ <b>AVISO OFICIAL:</b> {t['text']}{tag_linea}\nğŸ”— <a href='{t['link']}'>Ver Tweet</a>")
                break 
        except: continue

    return incidentes

def verificar_horario_servicio(ahora):
    dia = ahora.weekday(); hora = ahora.hour
    if dia <= 4 and hora == 5: return "ğŸš‡ <b>INICIO DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLa red del Metro inicia operaciones."
    elif dia == 5 and hora == 6: return "ğŸš‡ <b>INICIO DE SERVICIO (SÃBADO)</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nInicia operaciÃ³n de fin de semana."
    elif dia == 6 and hora == 7: return "ğŸš‡ <b>INICIO DE SERVICIO (DOMINGO)</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nServicio dominical iniciado."
    elif hora == 0: return "ğŸ’¤ <b>CIERRE DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nOperaciones concluidas por hoy."
    return None

def main():
    tz_mx = pytz.timezone('America/Mexico_City')
    ahora = datetime.now(tz_mx)
    print(f"ğŸ Escaneo iniciado: {ahora}")
    
    enviar_telegram("ğŸ“¡ <i>Conectando con la red de movilidad y analizando reportes ciudadanos...</i>")
    
    msg = verificar_horario_servicio(ahora)
    if msg: enviar_telegram(msg); return

    reportes = revisar_incidentes(ahora)
    if reportes:
        un = list(dict.fromkeys(reportes))
        h = ahora.strftime('%I:%M %p')
        enviar_telegram(f"ğŸš¨ <b>INCIDENCIAS DETECTADAS ({h})</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n" + "\n\n".join(un))
    else:
        print("âœ… Todo normal.")

if __name__ == "__main__":
    main()
