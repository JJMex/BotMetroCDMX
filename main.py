import os
import time
import requests
import feedparser
import pytz
import re
import urllib3
import json
from datetime import datetime, timedelta
from ntscraper import Nitter
from bs4 import BeautifulSoup
from fake_useragent import UserAgent
from urllib.parse import unquote

# 1. CONFIGURACIÃ“N TÃ‰CNICA
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ua = UserAgent()

# --- CREDENCIALES ---
TOKEN = os.environ.get('TELEGRAM_TOKEN')
ID_GRUPO = os.environ.get('TELEGRAM_CHAT_ID') 
ID_CANAL = os.environ.get('TELEGRAM_CHANNEL_ID') 
DESTINATARIOS = [id_ for id_ in [ID_GRUPO, ID_CANAL] if id_]

RSS_URL = "https://news.google.com/rss/search?q=Metro+CDMX+retraso+OR+falla+OR+caos+when:1h&hl=es-419&gl=MX&ceid=MX:es-419"

# --- DICCIONARIO DE INTELIGENCIA ---
# Mapea palabras clave a frases legibles
CAUSAS = {
    "retraso": "Retrasos", "lento": "Marcha Lenta", "lenta": "Marcha Lenta",
    "falla": "Falla TÃ©cnica", "averÃ­a": "AverÃ­a", "desalojo": "Desalojo de Tren",
    "humo": "Presencia de Humo", "fuego": "Conato de Incendio", "quemado": "Olor a Quemado",
    "zapatas": "Zapatas Pegadas", "lluvia": "Lluvia / Marcha de Seguridad", 
    "mojado": "Lluvia", "caos": "AglomeraciÃ³n Alta", "colapso": "Colapso",
    "espera": "Tiempos de Espera Altos", "detenido": "Tren Detenido", 
    "suicida": "Persona en VÃ­as", "arrollado": "Accidente en VÃ­as", 
    "corte": "Corte de Corriente", "bloqueo": "Bloqueo Exterior", 
    "cerrada": "EstaciÃ³n Cerrada", "sin servicio": "Sin Servicio"
}

PALABRAS_CLAVE = list(CAUSAS.keys()) + ["afectaciones", "avance", "servicio", "estaciones"]
PALABRAS_SOLUCION = ["restablece", "normal", "agiliza", "solucionado", "continuo", "reanuda", "opera con normalidad"]
IGNORAR = ["buenos dÃ­as", "cubrebocas", "tarjeta", "arte", "exposiciÃ³n", "domingos y dÃ­as festivos", "cultura", "museo", "simulacro"]
FIRMA = "\n\nâ€” ğŸ¤– <i>JJMex Bot</i>"

MAPA_LINEAS = {
    "1": "L1 (Rosa)", "uno": "L1 (Rosa)", "rosa": "L1 (Rosa)",
    "2": "L2 (Azul)", "dos": "L2 (Azul)", "azul": "L2 (Azul)",
    "3": "L3 (Verde)", "tres": "L3 (Verde)", "verde": "L3 (Verde)",
    "4": "L4 (Cian)", "cuatro": "L4 (Cian)", "cian": "L4 (Cian)",
    "5": "L5 (Amarilla)", "cinco": "L5 (Amarilla)", "amarilla": "L5 (Amarilla)",
    "6": "L6 (Roja)", "seis": "L6 (Roja)", "roja": "L6 (Roja)",
    "7": "L7 (Naranja)", "siete": "L7 (Naranja)", "naranja": "L7 (Naranja)",
    "8": "L8 (Verde)", "ocho": "L8 (Verde)", 
    "9": "L9 (CafÃ©)", "nueve": "L9 (CafÃ©)", "cafÃ©": "L9 (CafÃ©)",
    "a": "LA (FÃ©rrea)", "fÃ©rrea": "LA (FÃ©rrea)",
    "b": "LB (Gris)", "gris": "LB (Gris)",
    "12": "L12 (Dorada)", "doce": "L12 (Dorada)", "dorada": "L12 (Dorada)"
}

def get_headers():
    return {
        'User-Agent': ua.random,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Referer': 'https://news.google.com/'
    }

def enviar_telegram(mensaje):
    if not TOKEN or not DESTINATARIOS: return
    for chat_id in DESTINATARIOS:
        try:
            url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
            data = {'chat_id': chat_id, 'text': mensaje, 'parse_mode': 'HTML', 'disable_web_page_preview': True}
            requests.post(url, data=data, timeout=10)
        except: pass

# --- CEREBRO DE ANÃLISIS ---

def resolver_redireccion_google(url, fuente=""):
    """
    Inteligencia Anti-Bloqueo: Busca URLs que coincidan con la fuente de la noticia.
    """
    try:
        session = requests.Session()
        r = session.get(url, headers=get_headers(), timeout=10, verify=False, allow_redirects=True)
        
        basura = ["google", "gstatic", "youtube", "analytics", "doubleclick", "facebook", "twitter", "googletagmanager", "scorecardresearch"]
        
        if "google" in r.url:
            print(f"   âš ï¸ URL Ofuscada. Fuente esperada: '{fuente}'")
            # Limpiamos nombre de fuente para buscar coincidencia
            clean = fuente.lower().replace(" ", "").replace("tv", "").replace("noticias", "").replace("diario","")
            if len(clean) < 3: clean = "xxxxx" # Fallback

            # Buscamos todas las URLs en el HTML
            candidates = re.findall(r'(https?:\/\/[^"\s<>\\]+)', r.text)
            
            best_match = None
            generic_match = None
            
            for c in candidates:
                u = unquote(c).replace("\\u0026", "&").replace("\\", "")
                
                # Filtros bÃ¡sicos
                if any(b in u for b in basura): continue
                if len(u) < 25: continue
                if u.endswith(('.png','.jpg','.js','.css','.woff')): continue

                # Match de Fuente (Prioridad Alta)
                if clean in u.lower():
                    print(f"   ğŸ¯ MATCH DE FUENTE: {u[:50]}...")
                    return session.get(u, headers=get_headers(), timeout=10, verify=False)
                
                if not generic_match: generic_match = u
            
            # Si no hay match exacto, usamos el genÃ©rico
            target = best_match or generic_match
            if target: return session.get(target, headers=get_headers(), timeout=10, verify=False)
            
        return r
    except: return None

def espiar_web(url, fuente=""):
    """Extrae el texto real de la noticia"""
    try:
        resp = resolver_redireccion_google(url, fuente)
        if resp and resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            
            # 1. JSON-LD (Texto Oculto para Google)
            for s in soup.find_all('script', type='application/ld+json'):
                if s.string:
                    try:
                        d = json.loads(s.string)
                        if isinstance(d, list): d=d[0]
                        if 'articleBody' in d: return d['articleBody']
                    except: continue
            
            # 2. HTML (Limpieza Profunda)
            for t in soup(["script", "style", "nav", "footer", "header", "ads", "iframe", "aside", "form"]): t.extract()
            # Leemos pÃ¡rrafos y listas (importante para enumeraciones de lÃ­neas)
            textos = [t.get_text().strip() for t in soup.find_all(['p','li','h1','h2','h3']) if len(t.get_text().strip()) > 25]
            return " ".join(textos)
    except: pass
    return ""

def detectar_problemas_detallados(texto):
    """
    Analiza frase por frase para asociar LÃ­nea -> Problema.
    Retorna un string formateado para el mensaje.
    """
    texto = texto.lower()
    frases = re.split(r'[.;\n|]', texto) # Dividir por puntos o saltos
    reportes = {} # { "L3 (Verde)": "Marcha Lenta" }
    
    for f in frases:
        if len(f) < 10: continue
        
        lineas_en_frase = []
        for k, v in MAPA_LINEAS.items():
            # Buscar "Linea 3", "L3", "La 3"
            if re.search(fr'\b{k}\b' if k.isdigit() else k, f) or f"linea {k}" in f or f"l{k} " in f:
                lineas_en_frase.append(v)
        
        if lineas_en_frase:
            # Buscar causa en esa misma frase
            found_causes = [val for key, val in CAUSAS.items() if key in f]
            cause_txt = ", ".join(list(set(found_causes))) if found_causes else "Posible AfectaciÃ³n"
            
            for l in set(lineas_en_frase):
                # Guardamos la causa. Si ya existe "Posible", sobrescribimos con algo especÃ­fico.
                if l not in reportes or "Posible" in reportes[l]:
                    reportes[l] = cause_txt
    
    # Formatear salida bonita
    if reportes:
        items = sorted(reportes.items())
        # Formato: âš ï¸ L3 (Verde): Marcha Lenta
        return "\n".join([f"âš ï¸ <b>{k}:</b> {v}" for k, v in items])
    return ""

def revisar_todo(ahora):
    msgs = []
    
    # --- 1. GOOGLE NEWS RSS ---
    try:
        print("ğŸ” Escaneando Google News...")
        feed = feedparser.parse(RSS_URL)
        limite = ahora - timedelta(minutes=65)
        
        for e in feed.entries:
            if hasattr(e,'published_parsed'):
                dt = datetime(*e.published_parsed[:6], tzinfo=pytz.utc).astimezone(ahora.tzinfo)
                if dt > limite:
                    # Texto Base: TÃ­tulo + Resumen
                    txt_base = f"{e.title}. {e.summary if hasattr(e,'summary') else ''}"
                    fuente = e.source.title if hasattr(e,'source') else ""
                    
                    if any(w in txt_base.lower() for w in CAUSAS.keys()):
                        print(f"ğŸ‘‰ Detectado: {e.title[:30]}")
                        
                        # AnÃ¡lisis nivel 1 (RÃ¡pido)
                        detalles = detectar_problemas_detallados(txt_base)
                        
                        # AnÃ¡lisis nivel 2 (Profundo - Web Scraper)
                        if not detalles:
                            print("   ğŸ•µï¸ Escaneo profundo web activado...")
                            web_content = espiar_web(e.link, fuente)
                            detalles = detectar_problemas_detallados(txt_base + " " + web_content)
                        
                        # Icono de estado
                        emoji = "âœ…" if any(s in e.title.lower() for s in PALABRAS_SOLUCION) else "ğŸš¨"
                        
                        # Construir Mensaje
                        cuerpo = f"{emoji} <b>NOTICIA:</b> {e.title}\n"
                        if detalles:
                            cuerpo += f"\n{detalles}\n" # Insertamos la lista de lÃ­neas afectadas
                        cuerpo += f"ğŸ”— <a href='{e.link}'>Leer Nota Completa</a>"
                        
                        msgs.append(cuerpo)
    except Exception as ex: print(f"RSS Error: {ex}")

    # --- 2. TWITTER / NITTER ---
    for inst in ["nitter.privacydev.net", "nitter.net"]:
        try:
            print(f"ğŸ¦… Escaneando Twitter ({inst})...")
            scraper = Nitter(log_level=1, skip_instance_check=False, instance=inst)
            tweets = scraper.get_tweets("MetroCDMX", mode='user', number=4)
            if tweets and 'tweets' in tweets:
                for t in tweets['tweets']:
                    if "m" in t['date'] or "1h" in t['date']:
                        txt = t['text'].lower()
                        if any(w in txt for w in CAUSAS.keys()) and not any(ig in txt for ig in IGNORAR):
                            
                            detalles = detectar_problemas_detallados(txt)
                            emoji = "âœ…" if any(s in txt for s in PALABRAS_SOLUCION) else "ğŸš¨"
                            
                            cuerpo = f"{emoji} <b>OFICIAL:</b> {t['text']}\n"
                            if detalles: cuerpo += f"\n{detalles}\n"
                            cuerpo += f"ğŸ”— <a href='{t['link']}'>Ver Tweet</a>"
                            
                            msgs.append(cuerpo)
                break
        except: continue

    return msgs

def main():
    tz = pytz.timezone('America/Mexico_City')
    now = datetime.now(tz)
    print(f"ğŸ Inicio de Escaneo: {now}")
    
    enviar_telegram("ğŸ“¡ <i>Conectando con la red de movilidad y analizando reportes ciudadanos...</i>")
    
    # Horarios de Servicio
    d, h = now.weekday(), now.hour
    msg_h = None
    if d<=4 and h==5: msg_h = "ğŸš‡ <b>APERTURA DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nInicia operaciones dÃ­a hÃ¡bil."
    elif d==5 and h==6: msg_h = "ğŸš‡ <b>APERTURA SÃBADO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nInicia servicio de fin de semana."
    elif d==6 and h==7: msg_h = "ğŸš‡ <b>APERTURA DOMINGO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nInicia servicio dominical."
    elif h==0: msg_h = "ğŸ’¤ <b>CIERRE DE SERVICIO</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nBuenas noches, hasta maÃ±ana."
    
    if msg_h: enviar_telegram(msg_h + FIRMA); return

    # Buscar Incidentes
    alertas = revisar_todo(now)
    
    if alertas:
        # Eliminar duplicados exactos
        unicos = list(dict.fromkeys(alertas))
        
        # Cabecera con hora
        header = f"ğŸ“¢ <b>REPORTE METRO ({now.strftime('%I:%M %p')})</b>\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n"
        full_msg = header + "\n\n".join(unicos) + FIRMA
        
        enviar_telegram(full_msg)
    else:
        print("âœ… Sin novedades")
        enviar_telegram("âœ… <b>Sistema operando con normalidad.</b>\nSin reportes crÃ­ticos en la Ãºltima hora." + FIRMA)

if __name__ == "__main__":
    main()
